# FAI-RL: Framework for Aligned and Interactive Reinforcement Learning

A modular, production-ready library designed for **easy training, inference, and evaluation** of language models using reinforcement learning methods. Currently supports 
- DPO (Direct Preference Optimization),
- GRPO (Group Relative Preference Optimization), and
- GSPO (Group Sequence Policy Optimization).

## ğŸš€ Quick Start

Get started with installation, training, inference, and evaluation in just a few commands:

### ğŸ“¦ Installation

Follow these steps to set up the FAI-RL library on your local machine. The first time, you'll need to clone the repository, create a virtual environment, and install the required dependencies. For subsequent runs, you only need to activate the virtual environment.

#### Setup (first time only)

```bash
# Clone the repository
git clone https://github.com/Roblox/FAI-RL.git
cd FAI-RL

# Create virtual environment
python -m venv venv_fai_rl
source venv_rl_library/bin/activate

# Install dependencies
pip install -r requirements.txt
```

#### Next runs

```bash
source venv_fai_rl/bin/activate
```

### Training

Train a model using DPO, GRPO, or GSPO:

```bash
# Single GPU training
./scripts/run_training.sh \
    --config configs/training/dpo/llama3_3B_recipe.yaml \
    --num-gpus 1

# Multi-GPU training (8 GPUs)
./scripts/run_training.sh \
    --config configs/training/dpo/llama3_3B_recipe.yaml \
    --num-gpus 8 \
    --nohup  # Run in background
```

### Inference

Generate responses from your trained models:

```bash
# Run inference on trained model
./scripts/run_inference.sh \
    --config configs/inference/llama3_3B_recipe.yaml

# Run inference with debug mode
./scripts/run_inference.sh \
    --config configs/inference/llama3_3B_recipe.yaml \
    --debug
```

### Evaluation

Evaluate model performance on benchmarks:

```bash
# Evaluate on MMLU benchmark
./scripts/run_evaluation.sh \
    --config configs/evaluation/mmlu/llama3_3B_recipe.yaml

# Evaluate with debug output
./scripts/run_evaluation.sh \
    --config configs/evaluation/mmlu/llama3_3B_recipe.yaml \
    --debug
```

-----

## ğŸ“ Project Structure

```
FAI-RL/
â”œâ”€â”€ core/                      # Core framework components
â”œâ”€â”€ trainers/                  # Training method implementations
â”œâ”€â”€ inference/                 # Inference components
â”œâ”€â”€ evaluations/               # Evaluation system
â”œâ”€â”€ configs/                   # Configuration files
â”‚   â”œâ”€â”€ training/              # Training configurations
â”‚   â”œâ”€â”€ inference/             # Inference configurations
â”‚   â”œâ”€â”€ evaluation/            # Evaluation configurations
â”‚   â””â”€â”€ deepspeed/             # DeepSpeed ZeRO configurations
â”œâ”€â”€ utils/                     # Utility modules
â”œâ”€â”€ scripts/                   # Scripts
â”œâ”€â”€ logs/                      # Training logs (auto-generated)
â””â”€â”€ outputs/                   # Inference output (auto-generated)
```

-----

## ğŸ”— Quick Links

- **[Training Guide](./trainers/README.md)** - Configure and run model training
- **[Inference Guide](./inference/README.md)** - Run model inference and generation  
- **[Evaluation Guide](./evaluations/README.md)** - Evaluate model performance on benchmarks
